{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ix1cQ6_VSJXE"
      },
      "source": [
        "### Урок 5. #Задача оттока: варианты постановки, возможные способы решения##"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xYZTQHxrSJXI"
      },
      "source": [
        "План занятия:\n",
        "\n",
        "1. что такое \"отток\"?\n",
        "2. задача оттока как часть процесса под названием customer relationship management\n",
        "3. для чего его (отток) прогнозировать?\n",
        "4. удержание пользователей\n",
        "5. анализ аудитории\n",
        "6. метрики удержания\n",
        "7. области применения\n",
        "8. Как оценить эффективность удержания аудитории"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "DMp2ZifdSZQd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITpgIrqVSJXK"
      },
      "source": [
        "### Что такое \"отток\"?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2F-AvHnSJXK"
      },
      "source": [
        "Одно из определений:\n",
        "\n",
        "- отказ пользователя от некоторого продукта или услуги (сервиса)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_RXU-5fhSJXL"
      },
      "source": [
        "![ab_split](churn1.jpeg \"/content/drive/MyDrive/Colab Notebooks/машинное обучение в бизенесе/les_5/churn1.jpeg\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGte-UipSJXL"
      },
      "source": [
        "\"Интуитивно\" понятие оттока понятно - был пользователь, который пользовался нашим сервисом, а потом вдруг перестал это делать. Примеры: перешел в другой банк, в другую телекоммуникационную компанию, стал пользоваться другим сервисом и т.д (в зависимости от того, какая у нас сфера)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2pBs7YVSJXM"
      },
      "source": [
        "### customer relationship management"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wbt3zsHWSJXN"
      },
      "source": [
        "- выстраивание взаимоотношений с пользователем\n",
        "- успешность кампании зависит от того как устроена работа с пользователями"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nmi1ue6USJXO"
      },
      "source": [
        "Таким образом, задача оттока - это часть процесса по выстраиванию взаимоотношений с клиентами, а не просто задача в вакууме"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snQv0F7HSJXO"
      },
      "source": [
        "Чем лучше у нас выстроен процесс работы с пользователями, тем успешнее наш бизнес в целом"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dNAEcAmfSJXP"
      },
      "source": [
        "### Для чего прогнозировать отток?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JeSHHID4SJXP"
      },
      "source": [
        "- Чем больше у нас пользователей, тем выше прибыль (особенно, если большая доля выручки - это рекламная монетизация)\n",
        "- Больше пользователей = привлечение новых + удержание существующих (уменьшение оттока уже существующих)\n",
        "- У привлечения новых и удержания \"старых\" разная экономическая эффективность"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFzrCrxqSJXQ"
      },
      "source": [
        "#### Удержание стоит денег!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xX5MocvYSJXQ"
      },
      "source": [
        "Здесь вопрос уже в том, насколько \"дешево\" привлекать новых и \"дорого\" - удерживать старых"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3pLbpDppSJXR"
      },
      "source": [
        "Еще один момент - разные пользователи приносят нам разную прибыль (вспоминаем второе занятие)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiM0J1U9SJXR"
      },
      "source": [
        "![ab_split](payments.png \"Payments\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q0ZyqEP5SJXR"
      },
      "source": [
        "Очень может быть, что попробовать удержать \"китов\" будет гораздо выгоднее привлечения новых пользователей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "euI6JiMdSJXS"
      },
      "source": [
        "### Удержание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FEQ_quuwSJXS"
      },
      "source": [
        "![ab_split](churn2.png \"churn2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuBtLN1rSJXS"
      },
      "source": [
        "А что если удерживать всех пользователей?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kFZXottMSJXT"
      },
      "source": [
        "![ab_split](thinking.jpg \"thinking\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m1L19rUySJXT"
      },
      "source": [
        "Это будет очень дорого и неэффективно!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w0xbAJIsSJXT"
      },
      "source": [
        "Особенности процесса удержания:\n",
        "\n",
        "- адресное удержание\n",
        "- удержание происходит не всегда быстро (это занимает некоторое время + нужно оценить результаты)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSXRlqWfSJXU"
      },
      "source": [
        "Удержание состоит из следующих этапов:\n",
        "1. определить сегмент, кого удерживать (это как раз наша часть)\n",
        "2. определить, что предлагать\n",
        "3. сделать предложение\n",
        "4. дождаться реакции\n",
        "5. оценить результаты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Km5KpUn6SJXU"
      },
      "source": [
        "При этом прогноз должен быть сделан немного раньше, чем когда пользователь уже уйдет)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uaxwMlhJSJXU"
      },
      "source": [
        "### Анализ аудитории"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WEbP4q0lSJXU"
      },
      "source": [
        "Место задачи оттока в анализе поведения пользователей"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PCkT95SqSJXV"
      },
      "source": [
        "- описание аудитории (сегментация по разным показателям) - второе занятие\n",
        "- привлечение новых пользователей\n",
        "- работа с пользователями: вовлеченность, влияние на показатели\n",
        "- <b>прогнозирование оттока</b>\n",
        "- удержание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G27IimcXSJXV"
      },
      "source": [
        "### Метрики удержания"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UYOBcQupSJXV"
      },
      "source": [
        "- return rate (конверсия возврата)\n",
        "- churn rate (конверсия оттока)\n",
        "- N-day retention (удержание на день N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iEbyIoX4SJXV"
      },
      "source": [
        "return rate = (текущее количество активных пользователей из набора данных)/(общее количество пользователей из набора данных)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bYZOkn6SJXV"
      },
      "source": [
        "churn rate = (количество пользователей из набора данных, ушедших в отток)/(общее количество пользователей из набора данных)*100"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IQm3Vu8QSJXW"
      },
      "source": [
        "<b>Что значит фраза \"пользователь ушел в отток?\"</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nHd9J0AkSJXW"
      },
      "source": [
        "Ответ сильно зависит от сферы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38M8sMnFSJXW"
      },
      "source": [
        "В общем случае ответ на вроде бы простой вопрос \"ушел ли от нас пользователь\" - нетривиален"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "irEedbLKSJXW"
      },
      "source": [
        "#### Удержание N-го дня"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXc0oBfnSJXW"
      },
      "source": [
        "- 1-day retention\n",
        "- 3-day retention\n",
        "- 7-day retention\n",
        "- etc"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IJnyjnQCSJXX"
      },
      "source": [
        "Какая доля пользователей остается с нами на N-й день после установки (первой сессии)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t7JEkbJpSJXX"
      },
      "source": [
        "### Области применения"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C2A02tzfSJXX"
      },
      "source": [
        "- B2C\n",
        "- сферы, где распространение приближается к 100 процентам (приведите пример)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTeYSdftSJXX"
      },
      "source": [
        "Примеры:\n",
        "\n",
        "- банки\n",
        "- телеком\n",
        "- страховые компании\n",
        "- e-commerce, ритейл\n",
        "- мобильные сервисы\n",
        "- прочее"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PjG6IA-aSJXX"
      },
      "source": [
        "### Как оценить эффективность удержания аудитории"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4JzQ7rjVSJXY"
      },
      "source": [
        "Можно выделить несколько шагов:\n",
        "\n",
        "1. провести анализ аудитории: сегментация, ключевые показатели и т.д\n",
        "2. формализовать постановку задачи и построить модель\n",
        "3. запустить компанию по удержанию (с учетом прогнозов п.2) и оценить результаты"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GbJFxGM6SJXY"
      },
      "source": [
        "Анализ пользователей делается с целью ответить на следующие вопросы:\n",
        "\n",
        "1. существует ли проблема оттока в принципе\n",
        "2. доля пользователей, уходящих в отток\n",
        "3. сколько мы из-за этого теряем"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yL5PEytYSJXY"
      },
      "source": [
        "Неплохо еще построить экономическую модель, которая будет давать оценку в денежном выражении.\n",
        "\n",
        "Например: если у меня уходит X пользователей в сутки и я смогу удерживать Y из них, потратив N денег, то смогу ли я заработать больше N на их удержании?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYo5f8lkSJXY"
      },
      "source": [
        "Задачу точно имеет смысл решать, если вы сможете принести больше, чем потратите!\n",
        "\n",
        "В противном случае вопрос остается открытым"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "os5rIQkQSJXY"
      },
      "source": [
        "### Постановка задачи"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeAVbwIpSJXZ"
      },
      "source": [
        "0. Анализ аудитории\n",
        "1. определяем что мы считаем оттоком\n",
        "2. выбираем тип задачи (модели - бинарная/многоклассовая классификация, регрессия и т.д)\n",
        "3. определяем горизонт прогнозирования (с учетом времени на удержание)\n",
        "4. решаем, как именно мы будем оценивать качество нашей будущей модели (метрики)\n",
        "5. планируем дизайн эксперимента"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pf09f3x_SJXZ"
      },
      "source": [
        "Допустим, что мы умеем уже определить понятие \"отток\" (например, воспользовавшись методом из статьи https://arxiv.org/pdf/1907.03947.pdf)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhKulgt0SJXZ"
      },
      "source": [
        "Необходимо спланировать, как будет выглядеть кампания по удержанию"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2yYOspsTSJXZ"
      },
      "source": [
        "- какие у нас каналы взаимодействия с пользователем\n",
        "- какое время взаимодействия\n",
        "- что мы предлагаем"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLtV7z_RSJXZ"
      },
      "source": [
        "Теперь нам нужно вспомнить первое занятие и понятие \"продуктовой гипотезы\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44Y5IO8zSJXZ"
      },
      "source": [
        "Пример формулировки продуктовой гипотезы:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBpRiIdMSJXa"
      },
      "source": [
        "\"Базируясь на предположении, что модель машинного обучения сможет сегментировать пользователей на тех, кто уходит в отток и нет, <b>не превышая ошибку в X%</b>, мы предполагаем, что реализовав такую систему прогнозирования вероятности оттока, основанную на ML, мы сможем выделить сегмент пользователей, которые собираются уйти в отток и провести кампанию по удержанию, что приведет к тому, что большинство таких пользователей останутся с нами в будущем. Мы увидим это по <b>увеличению доли пользователей, оставшихся с нами на день N</b> ,и можем измерить ее с помощью метрики <b>удержание N-го дня</b>. Мы полагаем, что изменение приведет к хорошим результатам для компании, т.к увеличит удержание пользователей и, как следствие, увеличение выручки для компании\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-y54anaSJXa"
      },
      "source": [
        "Метрика1 (основная) - N-day retention\n",
        "\n",
        "* ML-модель может ошибаться и в итоге в кампанию по удержанию попадут в том числе и те игроки, которые не собирались от нас уходить. Как следствие, на их удержание будут потрачены деньги (им будет сделано более выгодное предложение, хотя этого можно было и не делать)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cSLWCeRFSJXa"
      },
      "source": [
        "### Сбор данных и построение модели"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTaXd5MySJXa"
      },
      "source": [
        "После того, как мы сформулировали гипотезу и выбрали метрику, мы можем уже собрать датасет и обучить модель"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LpQdMEPVSJXa"
      },
      "source": [
        "Во второй части занятия мы рассмотрим пример построения такой модели, а сейчас продолжим уже по шагам, представив что модель у нас уже есть"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "60rtIbjvSJXb"
      },
      "source": [
        "### Планирование эксперимента"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2rtjTNISJXb"
      },
      "source": [
        "При наличии модели с приемлемым качеством мы уже можем спланировать и провести эксперимент\n",
        "\n",
        "1. скорим всю нашу аудиторию модель прогнозирования оттока и получаем вероятности оттока для каждого пользователя\n",
        "2. сортируем пользователей по убыванию вероятности и берем топ Y%\n",
        "3. проводим кампанию по удержанию полученной выборки\n",
        "4. оцениваем результаты (превышает ли выручка от удержания расходы на это самое удержание)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t1cGbIq_SJXb"
      },
      "source": [
        "Не всегда эксперимент - это именно АБ-тестирование!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hb2tdHO-SJXb"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PdR7md2wSJXb"
      },
      "source": [
        "### Практика\n",
        "\n",
        "### Case 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1okCyE1jSJXc"
      },
      "source": [
        "Давайте поработаем с набором данных с платформы kaggle https://www.kaggle.com/adammaus/predicting-churn-for-bank-customers по оттоку клиентов банка"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7CtI3HOvSJXc"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.pipeline import Pipeline, make_pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "#from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "import itertools\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dWxJs2YiSJXd"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/машинное обучение в бизенесе/les_5/churn_data.csv\")\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tt89vlh8SJXe"
      },
      "source": [
        "Есть как категориальные, так и вещественные признаки. Поле CustomerId нужно будет удалить. \n",
        "\n",
        "Посмотрим на распределение классов:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G9OPw_uWSJXe"
      },
      "outputs": [],
      "source": [
        "df['Exited'].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34nOFXQqSJXf"
      },
      "source": [
        "Не самое плохое распределение (1 к 4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OVmAiPJpSJXf"
      },
      "source": [
        "Давайте построим модель. Сразу же будем работать с использованием sklearn pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w80Nb0tYSJXf"
      },
      "outputs": [],
      "source": [
        "#разделим данные на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(df, df['Exited'], random_state=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WSS0uUfpSJXf"
      },
      "source": [
        "- Категориальные признаки закодируем с помощью OneHotEncoding\n",
        "- Вещественные оставим пока как есть"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ltwjuVhASJXf"
      },
      "outputs": [],
      "source": [
        "#соберем наш простой pipeline, но нам понадобится написать класс для выбора нужного поля\n",
        "class FeatureSelector(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, column):\n",
        "        self.column = column\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X, y=None):\n",
        "        return X[self.column]\n",
        "    \n",
        "class NumberSelector(BaseEstimator, TransformerMixin):\n",
        "    \"\"\"\n",
        "    Transformer to select a single column from the data frame to perform additional transformations on\n",
        "    Use on numeric columns in the data\n",
        "    \"\"\"\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        return X[[self.key]]\n",
        "    \n",
        "class OHEEncoder(BaseEstimator, TransformerMixin):\n",
        "    def __init__(self, key):\n",
        "        self.key = key\n",
        "        self.columns = []\n",
        "\n",
        "    def fit(self, X, y=None):\n",
        "        self.columns = [col for col in pd.get_dummies(X, prefix=self.key).columns]\n",
        "        return self\n",
        "\n",
        "    def transform(self, X):\n",
        "        X = pd.get_dummies(X, prefix=self.key)\n",
        "        test_columns = [col for col in X.columns]\n",
        "        for col_ in self.columns:\n",
        "            if col_ not in test_columns:\n",
        "                X[col_] = 0\n",
        "        return X[self.columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2V9FmZf3SJXg"
      },
      "outputs": [],
      "source": [
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79MzCFAQSJXg"
      },
      "source": [
        "Зададим списки признаков"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M0lyAflJSJXg"
      },
      "outputs": [],
      "source": [
        "categorical_columns = ['Geography', 'Gender', 'Tenure', 'HasCrCard', 'IsActiveMember']\n",
        "continuous_columns = ['CreditScore', 'Age', 'Balance', 'NumOfProducts', 'EstimatedSalary']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "64B7viY1SJXg"
      },
      "source": [
        "Посмотрим как это работает на примере отдельного категориального признака - Gender"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9dW3zLsPSJXh"
      },
      "outputs": [],
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.pipeline import FeatureUnion\n",
        "\n",
        "gender = Pipeline([\n",
        "                ('selector', FeatureSelector(column='Gender')),\n",
        "                ('ohe', OHEEncoder(key='Gender'))\n",
        "            ])\n",
        "gender.fit(X_train)\n",
        "gender.transform(X_test).head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPafoJSRSJXh"
      },
      "source": [
        "Ананлогичный пример для вещественного признака (здесь мы не применяем какое-либо преобразование, а просто столбец как есть)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2WwK11ijSJXh"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8XWAZDGSJXh"
      },
      "source": [
        "Теперь нам нужно под каждый признак создать трансформер и объединить их в список (сделаем это в цикле, чтобы не мучиться)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-2xXGLabSJXi"
      },
      "outputs": [],
      "source": [
        "final_transformers = list()\n",
        "\n",
        "for cat_col in categorical_columns:\n",
        "    cat_transformer = Pipeline([\n",
        "                ('selector', FeatureSelector(column=cat_col)),\n",
        "                ('ohe', OHEEncoder(key=cat_col))\n",
        "            ])\n",
        "    final_transformers.append((cat_col, cat_transformer))\n",
        "    \n",
        "for cont_col in continuous_columns:\n",
        "    cont_transformer = Pipeline([\n",
        "                ('selector', NumberSelector(key=cont_col)),\n",
        "                ('scaler', StandardScaler())\n",
        "            ])\n",
        "    final_transformers.append((cont_col, cont_transformer))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ld2Imu3gSJXi"
      },
      "source": [
        "Объединим все это в единый пайплайн"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bcmneoGjSJXi"
      },
      "outputs": [],
      "source": [
        "feats = FeatureUnion(final_transformers)\n",
        "\n",
        "feature_processing = Pipeline([('feats', feats)])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZaSo63PqSJXi"
      },
      "source": [
        "Теперь у нас есть пайплайн, который готовит признаки для моделирования.\n",
        "\n",
        "Добавим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bl4tGF6kSJXj"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('features',feats),\n",
        "    #('classifier', RandomForestClassifier(random_state = 42)\n",
        "    #('classifier', GradientBoostingClassifier(n_estimators=300, learning_rate=1.0, max_depth=1, random_state=66)\n",
        "    ('classifier', LogisticRegression(random_state=66)\n",
        "    ),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f3GQouwdSJXj"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D8FwygfhSJXj"
      },
      "source": [
        "Обучим модель"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": false,
        "id": "AOSL8OGnSJXj"
      },
      "outputs": [],
      "source": [
        "#обучим наш пайплайн\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c5ZRIP5nSJXj"
      },
      "outputs": [],
      "source": [
        "#наши прогнозы для тестовой выборки\n",
        "preds = pipeline.predict_proba(X_test)[:, 1]\n",
        "preds[:10]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLjRALYWSJXk"
      },
      "source": [
        "Также нам нужно от вероятностей перейти к меткам классов. Для этого нужно подобрать порог, после которого мы считаем, что объект можно отнести к классу 1 (если вероятность больше порога - размечаем объект как класс 1, если нет - класс 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QT-YcX-VSJXk"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score, roc_auc_score, precision_score, classification_report, precision_recall_curve, confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w3mftYGzSJXk"
      },
      "outputs": [],
      "source": [
        "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
        "\n",
        "fscore = (2 * precision * recall) / (precision + recall)\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscore)\n",
        "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
        "                                                                        fscore[ix],\n",
        "                                                                        precision[ix],\n",
        "                                                                        recall[ix]))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Метрика для ДЗ GradientBoostingClassifier(n_estimators=300, learning_rate=1.0, max_depth=1, random_state=66) \n",
        " \n",
        "Best Threshold=0.337333, F-Score=0.622, Precision=0.588, Recall=0.660\n",
        "1. Метрика для ДЗ LogisticRegression(max_iter=110, solver=\"sag\", tol=1e-1) \n",
        "\n",
        "Best Threshold=0.286622, F-Score=0.509, Precision=0.471, Recall=0.552\n",
        "\n",
        "1. Метрика для ДЗ RandomForestClassifier(random_state = 42)\n",
        "\n",
        "Best Threshold=0.380000, F-Score=0.641, Precision=0.654, Recall=0.629\n"
      ],
      "metadata": {
        "id": "64g-8fff9AZr"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "14qtvxzQSJXn"
      },
      "source": [
        "#### Вопрос 1: объясните своими словами смысл метрик Precison, Recall *\n",
        "1. Какова их взаимосвязь и как с ними связан порог вероятности? \n",
        "2. Можно ли подобрать порог так, что recall будет равен 1? Что при этом будет с precision\n",
        "3. Аналогичный вопрос про precision"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5X0qo3rySJXn"
      },
      "source": [
        "Ваш ответ здесь:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iZG6r4vqSJXn"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mr7V2qcbSJXn"
      },
      "source": [
        "Отрисуем матрицу ошибок"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B9Tyox1JSJXn"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        print('Confusion matrix, without normalization')\n",
        "\n",
        "    print(cm)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AkzZN-0hSJXo"
      },
      "outputs": [],
      "source": [
        "#мы уже нашли ранее \"оптимальный\" порог, когда максимизировали f_score\n",
        "font = {'size' : 15}\n",
        "\n",
        "plt.rc('font', **font)\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, preds>thresholds[ix])\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['NonChurn', 'Churn'],\n",
        "                      title='Confusion matrix')\n",
        "plt.savefig(\"conf_matrix.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Le81FcqQSJXo"
      },
      "source": [
        "Можно заметить, что мы очень сильно ошибаемся в сторону False Negatives, т.е у нас много тех, кто ушел в отток на самом деле, но при выбранном нами пороге в 0.38 мы не считаем их таковыми. "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. Метрика для ДЗ  GradientBoostingClassifier(n_estimators=300, learning_rate=1.0, max_depth=1, random_state=66)\n",
        "\n",
        "Confusion matrix\n",
        "\n",
        "\n",
        "[[1756  235]\n",
        "\n",
        " [ 174  335]]\n",
        "\n",
        " 2. Метрика для ДЗ LogisticRegression\n",
        "\n",
        " Confusion matrix\n",
        "\n",
        "[[1676  315]\n",
        "\n",
        " [ 229  280]]\n",
        "\n",
        "  2. Метрика для ДЗ RandomForestClassifier(random_state = 42)\n",
        "\n",
        "  [[1833  158]\n",
        "  \n",
        " [ 195  314]]"
      ],
      "metadata": {
        "id": "-N3-IkYv9S_1"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPJ5OreCSJXo"
      },
      "source": [
        "<b>Вопрос 2: предположим, что на удержание одного пользователя у нас уйдет 1 доллар. При этом средняя ожидаемая прибыль с каждого TP (true positive) - 2 доллара. Оцените качество модели выше с учетом этих данных и ответьте на вопрос, является ли она потенциально экономически целесообразной?</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRRe_hfiSJXp"
      },
      "source": [
        "Ваш ответ здесь: "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "TtKXthCW9o7R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Оценка экономических затрат для ДЗ"
      ],
      "metadata": {
        "id": "14NGdZ0LDDMZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tiaol8yXSJXp"
      },
      "outputs": [],
      "source": [
        "((1833)*2)-((195+314)+(158*2))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Модель является потенциально прибыльной без учёта остальных затрат"
      ],
      "metadata": {
        "id": "PrY2IJ-i8N0o"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzwE41aASJXp"
      },
      "source": [
        "### Пример с перебором параметров с помощью GridSearch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdxHp1wKSJXp"
      },
      "source": [
        "Сетка с параметрами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k_kasyzwSJXp"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "params={#'classifier__max_features':[0.3, 0.5, 0.7],\n",
        "        #'classifier__min_samples_leaf':[1, 2, 3],\n",
        "        #'classifier__max_depth':[1, 2, 3],\n",
        "        #'classifier__n_estimators': [100, 200, 300, 400],\n",
        "        #'classifier__learning_rate' : [0.5, 0.7, 0.9, 1.0]\n",
        "        'classifier__tol' : [0.0001, 0.0005, 0.0005, 0.0009],\n",
        "        'classifier__max_iter' : [100, 500, 1000, 2000]\n",
        "\n",
        "        }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YDhHWkThSJXq"
      },
      "source": [
        "Запускаем перебор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "8Jfyfv5jSJXq"
      },
      "outputs": [],
      "source": [
        "#grid = GridSearchCV(pipeline,\n",
        "                    #param_grid=params,\n",
        "                    #cv=6,\n",
        "                    #refit=False)\n",
        "\n",
        "#search = grid.fit(X_train, y_train)\n",
        "#search.best_params_"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KHusZx8uSJXq"
      },
      "source": [
        "Обучаем модель уже сновыми параметрами"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I9YuDgO6SJXq"
      },
      "outputs": [],
      "source": [
        "pipeline = Pipeline([\n",
        "    ('features',feats),\n",
        "    #('classifier', GradientBoostingClassifier(n_estimators=300, learning_rate=1.0, max_depth=1, random_state=66))\n",
        "    #('classifier', RandomForestClassifier(max_depth=None, max_features=0.3, \n",
        "                                         # min_samples_leaf=3, random_state=42))\n",
        "    ('classifier', LogisticRegression(max_iter=2000, C=1e5, tol=0.0001, random_state=66))\n",
        "])\n",
        "pipeline.fit(X_train, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "959DULpTSJXr"
      },
      "outputs": [],
      "source": [
        "preds = pipeline.predict_proba(X_test)[:, 1]\n",
        "precision, recall, thresholds = precision_recall_curve(y_test, preds)\n",
        "fscore = (2 * precision * recall) / (precision + recall)\n",
        "# locate the index of the largest f score\n",
        "ix = np.argmax(fscore)\n",
        "print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f' % (thresholds[ix], \n",
        "                                                                        fscore[ix],\n",
        "                                                                        precision[ix],\n",
        "                                                                        recall[ix]))\n",
        "\n",
        "#мы уже нашли ранее \"оптимальный\" порог, когда максимизировали f_score\n",
        "font = {'size' : 15}\n",
        "\n",
        "plt.rc('font', **font)\n",
        "\n",
        "cnf_matrix = confusion_matrix(y_test, preds>thresholds[ix])\n",
        "plt.figure(figsize=(10, 8))\n",
        "plot_confusion_matrix(cnf_matrix, classes=['NonChurn', 'Churn'],\n",
        "                      title='Confusion matrix')\n",
        "plt.savefig(\"conf_matrix.png\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhZkkTaUSJXr"
      },
      "source": [
        "Метрики немного стали выше"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9-mhD7TpSJXr"
      },
      "source": [
        "### ПЕРЕРЫВ до 21:05 (МСК)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nomCESISJXr"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jEOJffTpSJXs"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X5facoItSJXs"
      },
      "source": [
        "### Кейс 2. Отток пользователей в онлайн-игре\n",
        "\n",
        "https://mlbootcamp.ru/ru/round/10/sandbox/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tRtdh389SJXs"
      },
      "source": [
        "В этой задаче необходимо научиться предсказывать, остается ли участник в он-лайн игре или уходит из нее. Уходом считается отсутствие его в игре в течение недели.\n",
        "\n",
        " \n",
        "\n",
        "Всего используется 12 признаков, вычисленных за 2 предыдущие недели:\n",
        "\n",
        "- maxPlayerLevel - максимальный уровень игры, который прошел игрок\n",
        "- numberOfAttemptedLevels - количество уровней, которые попытался пройти игрок\n",
        "- attemptsOnTheHighestLevel - число попыток, сделанных на самом высоком уровне\n",
        "- totalNumOfAttempts - общее число попыток\n",
        "- averageNumOfTurnsPerCompletedLevel - среднее количество ходов, выполненных на успешно пройденных уровнях\n",
        "- doReturnOnLowerLevels - делал ли игрок возвраты к игре на уже пройденных уровнях\n",
        "- numberOfBoostersUsed - количество использованных бустеров\n",
        "- fractionOfUsefullBoosters - количество бустеров, использованных во время успешных попыток (игрок прошел уровнь)\n",
        "- totalScore - общее количество набранных очков\n",
        "- totalBonusScore - общее количество набранных бонусных очков\n",
        "- totalStarsCount - общее количество набранных звезд\n",
        "- numberOfDaysActuallyPlayed - количество дней, когда пользователь играл в игру\n",
        "\n",
        "Все предоставленные для задачи данные разбиты на две части: обучающую (x_train.csv и y_train.csv) и тестовую (x_test.csv). Каждая строка файлов x_train.csv и x_test.csv соответствует одному пользователю. Данные в строке разделены точкой с запятой. Первая строка содержит имена признаков. Файл y_train.csv содержит значения 1 или 0 в зависимости от того, остался пользователь в игре или вышел из нее соответственно.\n",
        "\n",
        "Как обучающая (x_train.csv и y_train.csv), так и тестовая (x_test.csv) выборки содержат информацию о 25289 пользователях."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l3WvylleSJXs"
      },
      "source": [
        "Решение победителя https://habr.com/ru/post/324916/ (немного адаптированное)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UqxZus8-SJXt"
      },
      "outputs": [],
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import log_loss\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from datetime import datetime as dt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "import random\n",
        "\n",
        "random.seed(666)\n",
        "import warnings\n",
        "\n",
        "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JqSICMeLSJXt"
      },
      "outputs": [],
      "source": [
        "def loss_func(y_true, y_pred):\n",
        "    return log_loss(y_true, y_pred)\n",
        "\n",
        "\n",
        "all_train = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/машинное обучение в бизенесе/les_5/x_train.csv', sep=';')\n",
        "all_target = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/машинное обучение в бизенесе/les_5/y_train.csv', sep=';', names=['TARGET'])\n",
        "all_train['TARGET'] = all_target['TARGET']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFIYRzNxSJXt"
      },
      "outputs": [],
      "source": [
        "#разделим данные на train/test\n",
        "X_train, X_test, y_train, y_test = train_test_split(all_train, all_train['TARGET'], random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "trCFBj0jSJXt"
      },
      "outputs": [],
      "source": [
        "cols_to_drop = ['ID', 'TARGET']\n",
        "cols = list(set(all_train.columns) - set(cols_to_drop))\n",
        "base_cols = cols"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-kxcTaZnSJXu"
      },
      "outputs": [],
      "source": [
        "# определи группы одинаковых строк\n",
        "X_train['row_id'] = X_train[base_cols].apply(lambda row: '_'.join([str(i) for i in row]), axis=1)\n",
        "X_test['row_id'] = X_test[base_cols].apply(lambda row: '_'.join([str(i) for i in row]), axis=1)\n",
        "\n",
        "gb = X_train.groupby(['row_id'], as_index=False).size()\n",
        "gb.name = 'size'\n",
        "gb = gb.reset_index()\n",
        "sizdata = gb[gb['size'] > 50].sort_values('size', ascending=False)\n",
        "\n",
        "similar_data = X_train[X_train['row_id'].isin(sizdata['row_id'].values)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zppRK23XSJXu"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "GjRbo9s2SJXu"
      },
      "outputs": [],
      "source": [
        "# генерируем признаки\n",
        "def transform_data(data):\n",
        "    for i1, col1 in enumerate(base_cols):\n",
        "        data[col1 + '_log'] = np.log(data[col1] + 1.1)\n",
        "\n",
        "        for i2, col2 in enumerate(base_cols):\n",
        "            data['%s_%s_1' % (col1, col2)] = data[col1] - data[col2]\n",
        "            data['%s_%s_2' % (col1, col2)] = data[col1] + data[col2]\n",
        "            data['%s_%s_3' % (col1, col2)] = data[col1] / (data[col2] + 0.1)\n",
        "            data['%s_%s_4' % (col1, col2)] = data[col1] * data[col2]\n",
        "\n",
        "            data['%s_%s_11' % (col1, col2)] = data[col1] - np.log(data[col2] + 1)\n",
        "            data['%s_%s_22' % (col1, col2)] = data[col1] + np.log(data[col2] + 1)\n",
        "            data['%s_%s_33' % (col1, col2)] = data[col1] / (np.log(data[col2] + 1) + 0.1)\n",
        "            data['%s_%s_44' % (col1, col2)] = data[col1] * np.log(data[col2] + 1)\n",
        "\n",
        "    return data\n",
        "\n",
        "\n",
        "X_train_tr = transform_data(X_train)\n",
        "X_test_tr = transform_data(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9cVBEdUHSJXu"
      },
      "outputs": [],
      "source": [
        "cols = [col for col in X_train_tr.drop(['TARGET', 'row_id'], 1).columns]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tmLMCHBfSJXv"
      },
      "outputs": [],
      "source": [
        "len(cols)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jS5BcxiaSJXv"
      },
      "outputs": [],
      "source": [
        "# выборки для разных моделей\n",
        "X_train_gb = X_train[cols].values\n",
        "\n",
        "scaler_reg = MinMaxScaler((-1, 1))\n",
        "scaler_reg.fit(np.vstack((X_train_tr[cols], X_test_tr[cols])))\n",
        "X_train_reg = scaler_reg.transform(X_train_tr[cols])\n",
        "X_test_reg = scaler_reg.transform(X_test_tr[cols])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "P8bl6VUlSJXv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "7VmNs7qySJXv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8fcd2f-b12c-4115-dd3b-4701f5917072"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      Iter       Train Loss      OOB Improve   Remaining Time \n",
            "         1           0.8753           0.0308           34.29s\n",
            "         2           0.8496           0.0267           35.15s\n",
            "         3           0.8236           0.0235           35.40s\n",
            "         4           0.8015           0.0209           35.69s\n",
            "         5           0.7873           0.0190           35.08s\n",
            "         6           0.7723           0.0169           34.88s\n",
            "         7           0.7530           0.0152           34.47s\n",
            "         8           0.7400           0.0135           34.57s\n",
            "         9           0.7256           0.0114           34.24s\n",
            "        10           0.7173           0.0098           34.08s\n",
            "        20           0.6575           0.0027           32.75s\n",
            "        30           0.6407           0.0006           31.50s\n",
            "        40           0.6408           0.0001           30.14s\n",
            "        50           0.6324          -0.0000           28.77s\n",
            "        60           0.6308          -0.0001           27.52s\n",
            "        70           0.6363          -0.0000           26.25s\n",
            "        80           0.6329          -0.0000           25.05s\n",
            "        90           0.6305          -0.0000           23.89s\n",
            "       100           0.6158          -0.0004           22.74s\n",
            "       200           0.6165          -0.0001           11.32s\n"
          ]
        }
      ],
      "source": [
        "# ------------------------------------------------------------------\n",
        "params = {\n",
        "    'silent': 1,\n",
        "    'objective': 'binary:logistic',\n",
        "    'max_depth': 4,\n",
        "    'eta': 0.01,\n",
        "    'subsample': 0.4,\n",
        "    'min_child_weight': 7,\n",
        "    'n': 580,\n",
        "    'verbose': 1\n",
        "}\n",
        "\n",
        "dtrain = xgb.DMatrix(X_train_tr[cols], label=y_train, missing=np.NaN)\n",
        "\n",
        "\n",
        "bst1 = xgb.XGBClassifier(boosting_type='gbdt', **params)\n",
        "bst1.fit(X_train_tr[cols], y_train)\n",
        "# ------------------------------------------------------------------\n",
        "params_est = {\n",
        "    'n_estimators': 300,\n",
        "    'loss': 'exponential',\n",
        "    'learning_rate': 0.08,\n",
        "    'subsample': 0.6910000000000001,\n",
        "    'min_samples_leaf': 340,\n",
        "    'max_features': 53,\n",
        "    'random_state': 1,\n",
        "    'verbose': 1\n",
        "}\n",
        "bst2 = GradientBoostingClassifier(**params_est)\n",
        "bst2.fit(X_train_tr[cols], y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "9TyWYS1VSJXw"
      },
      "outputs": [],
      "source": [
        "#обычная логистическая регрессия\n",
        "bst3 = LogisticRegression()\n",
        "bst3.fit(X_train_reg, y_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tN6BppaSSJXw"
      },
      "source": [
        "Посчитаем скоры"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yQRd3c34SJXw"
      },
      "outputs": [],
      "source": [
        "t1 = bst1.predict_proba(X_test_tr[cols])[:, 1]\n",
        "t2 = bst2.predict_proba(X_test_tr[cols].values)[:,1]\n",
        "t3 = bst3.predict_proba(X_test_reg)[:,1]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4XICqiZKSJXw"
      },
      "source": [
        "Объединим все"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "91Va-XESSJXx"
      },
      "outputs": [],
      "source": [
        "results = pd.DataFrame({'y_true': y_test,\n",
        "              'XGB': t1,\n",
        "              'GBM': t2,\n",
        "              'LR': t3})\n",
        "results['AVG_xgb_gbm_lr'] = results[['XGB', 'GBM', 'LR']].mean(axis=1)\n",
        "results['AVG_xgb_lr'] = results[['XGB', 'LR']].mean(axis=1)\n",
        "results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A-Y0pNPSJXx"
      },
      "source": [
        "Посчитаем метрики"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z3INu1ZlSJXx"
      },
      "outputs": [],
      "source": [
        "def get_metrics(probs):\n",
        "    precision, recall, thresholds = precision_recall_curve(y_test, probs)\n",
        "\n",
        "    fscore = (2 * precision * recall) / (precision + recall)\n",
        "    # locate the index of the largest f score\n",
        "    ix = np.argmax(fscore)\n",
        "    print('Best Threshold=%f, F-Score=%.3f, Precision=%.3f, Recall=%.3f, Roc-AUC=%.3f' % (thresholds[ix], \n",
        "                                                                            fscore[ix],\n",
        "                                                                            precision[ix],\n",
        "                                                                            recall[ix],\n",
        "                                                                            roc_auc_score(y_test, probs)))\n",
        "    return thresholds[ix]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCBOHAv3SJXx"
      },
      "outputs": [],
      "source": [
        "xgb_th = get_metrics(results['XGB'])\n",
        "gbm_th = get_metrics(results['GBM'])\n",
        "lr_th = get_metrics(results['LR'])\n",
        "blending_th = get_metrics(results['AVG_xgb_gbm_lr'])\n",
        "blending2_th = get_metrics(results['AVG_xgb_lr'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gx2D4hNxSJXx"
      },
      "source": [
        "Ничего особенного блендинг нам не дает, но вполне возможно, что при большем количестве моделей результат может быть иным. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sNR72GfjSJXy"
      },
      "source": [
        "### Домашнее задание"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ZYRqTHYSJXy"
      },
      "source": [
        "1. Для нашего пайплайна (Case1) поэкспериментировать с разными моделями: 1 - бустинг, 2 - логистическая регрессия (не забудьте здесь добавить в cont_transformer стандартизацию - нормирование вещественных признаков)\n",
        "2. Отобрать лучшую модель по метрикам (кстати, какая по вашему мнению здесь наиболее подходящая DS-метрика)\n",
        "3. Для отобранной модели (на отложенной выборке) сделать оценку экономической эффективности при тех же вводных, как в вопросе 2 (1 доллар на привлечение, 2 доллара - с каждого правильно классифицированного (True Positive) удержанного). (подсказка) нужно посчитать FP/TP/FN/TN для выбранного оптимального порога вероятности и посчитать выручку и траты. \n",
        "4. (опционально) Провести подбор гиперпараметров лучшей модели по итогам 2-3\n",
        "5. (опционально) Еще раз провести оценку экономической эффективности"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "B_h1i9yk2IJv"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uG-YYaGcSJXy"
      },
      "source": [
        "### Ссылки"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Vkr33ZfhSJXy"
      },
      "source": [
        "1. http://hyperopt.github.io/hyperopt/\n",
        "2. https://arxiv.org/pdf/1907.03947.pdf\n",
        "3. https://arxiv.org/pdf/1802.02301.pdf\n",
        "4. https://arxiv.org/list/stat.ML/recent\n",
        "5. https://scikit-learn.org/stable/modules/grid_search.html\n",
        "6. https://scikit-learn.org/stable/modules/compose.html"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JgK20hgMSJXy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.8"
    },
    "colab": {
      "name": "webinar5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}